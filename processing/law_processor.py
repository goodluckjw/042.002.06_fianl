import requests
import xml.etree.ElementTree as ET
from urllib.parse import quote
import re
import os

OC = os.getenv("OC", "chetera")
BASE = "http://www.law.go.kr"

def get_law_list_from_api(query):
    exact_query = f'"{query}"'
    encoded_query = quote(exact_query)
    page = 1
    laws = []
    while True:
        url = f"{BASE}/DRF/lawSearch.do?OC={OC}&target=law&type=XML&display=100&page={page}&search=2&knd=A0002&query={encoded_query}"
        res = requests.get(url, timeout=10)
        res.encoding = 'utf-8'
        if res.status_code != 200:
            break
        root = ET.fromstring(res.content)
        for law in root.findall("law"):
            laws.append({
                "ë²•ë ¹ëª…": law.findtext("ë²•ë ¹ëª…í•œê¸€", "").strip(),
                "MST": law.findtext("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸", ""),
                "URL": BASE + (law.findtext("ë²•ë ¹ìƒì„¸ë§í¬", "") or "")
            })
        if len(root.findall("law")) < 100:
            break
        page += 1
    return laws

def get_law_text_by_mst(mst):
    url = f"{BASE}/DRF/lawService.do?OC={OC}&target=law&MST={mst}&type=XML"
    try:
        res = requests.get(url, timeout=10)
        res.encoding = 'utf-8'
        return res.content if res.status_code == 200 else None
    except:
        return None

def clean(text):
    return re.sub(r"\s+", "", text or "")

def highlight(text, keyword):
    if not text:
        return ""
    return text.replace(keyword, f"<span style='color:red'>{keyword}</span>")

def get_highlighted_articles(mst, keyword):
    xml_data = get_law_text_by_mst(mst)
    if not xml_data:
        return "âš ï¸ ë³¸ë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    tree = ET.fromstring(xml_data)
    articles = tree.findall(".//ì¡°ë¬¸ë‹¨ìœ„")
    keyword_clean = clean(keyword)
    results = []

    for article in articles:
        ì¡°ë²ˆí˜¸ = article.findtext("ì¡°ë²ˆí˜¸", "").strip()
        ì¡°ì œëª© = article.findtext("ì¡°ë¬¸ì œëª©", "") or ""
        ì¡°ë‚´ìš© = article.findtext("ì¡°ë¬¸ë‚´ìš©", "") or ""
        í•­ë“¤ = article.findall("í•­")

        ì¡°ì¶œë ¥ = False
        í•­ì¶œë ¥ = []

        for i, í•­ in enumerate(í•­ë“¤):
            í•­ë‚´ìš© = í•­.findtext("í•­ë‚´ìš©", "") or ""
            í˜¸ì¶œë ¥ = []

            for í˜¸ in í•­.findall("í˜¸"):
                í˜¸ë‚´ìš© = í˜¸.findtext("í˜¸ë‚´ìš©", "") or ""
                if keyword_clean in clean(í˜¸ë‚´ìš©):
                    í˜¸ì¶œë ¥.append("&nbsp;&nbsp;" + highlight(í˜¸ë‚´ìš©, keyword))
            for ëª© in í•­.findall("ëª©"):
                ì¤„ë‹¨ìœ„ = []
                for m in ëª©.findall("ëª©ë‚´ìš©"):
                    if m.text and keyword_clean in clean(m.text):
                        ì¤„ë‹¨ìœ„.extend([
                            "&nbsp;&nbsp;&nbsp;&nbsp;" + highlight(line.strip(), keyword)
                            for line in m.text.splitlines() if line.strip()
                        ])
                if ì¤„ë‹¨ìœ„:
                    í˜¸ì¶œë ¥.extend(ì¤„ë‹¨ìœ„)

            if keyword_clean in clean(í•­ë‚´ìš©):
                í•­ì¶œë ¥.append(highlight(í•­ë‚´ìš©, keyword))
                if í˜¸ì¶œë ¥:
                    í•­ì¶œë ¥.extend(í˜¸ì¶œë ¥)
            elif í˜¸ì¶œë ¥:
                í•­ì¶œë ¥.append(highlight(í•­ë‚´ìš©, keyword) + "<br>" + "<br>".join(í˜¸ì¶œë ¥))

        if keyword_clean in clean(ì¡°ì œëª©) or keyword_clean in clean(ì¡°ë‚´ìš©) or í•­ì¶œë ¥:
            output = f"{highlight(ì¡°ë‚´ìš©, keyword)}"
            if í•­ì¶œë ¥:
                output += " " + í•­ì¶œë ¥[0]
                if len(í•­ì¶œë ¥) > 1:
                    output += "<br>" + "<br>".join([f"&nbsp;&nbsp;{a}" for a in í•­ì¶œë ¥[1:]])
            results.append(output)

    return "<br><br>".join(results) if results else "ğŸ” í•´ë‹¹ ê²€ìƒ‰ì–´ë¥¼ í¬í•¨í•œ ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."

def run_search_logic(query, unit):
    result = {}
    for law in get_law_list_from_api(query):
        mst = law["MST"]
        html = get_highlighted_articles(mst, query)
        if html and "í•´ë‹¹ ê²€ìƒ‰ì–´ë¥¼ í¬í•¨í•œ ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤" not in html:
            result[law["ë²•ë ¹ëª…"]] = html.split("<br><br>")
    return result

def run_amendment_logic(find_word, replace_word):
    ì¡°ì‚¬ = "ì„" if (ord(find_word[-1]) - 44032) % 28 else "ë¥¼"
    amendments = []
    for law in get_law_list_from_api(find_word):
        mst = law["MST"]
        xml = get_law_text_by_mst(mst)
        if not xml:
            continue
        tree = ET.fromstring(xml)
        articles = tree.findall(".//ì¡°ë¬¸ë‹¨ìœ„")
        ì¡°ë¬¸ë“¤ = []
        for article in articles:
            ì¡°ë²ˆí˜¸ = article.findtext("ì¡°ë²ˆí˜¸", "").strip()
            ì¡°ì œëª© = article.findtext("ì¡°ë¬¸ì œëª©", "") or ""
            ì¡°ë‚´ìš© = article.findtext("ì¡°ë¬¸ë‚´ìš©", "") or ""
            if find_word in ì¡°ì œëª©:
                ì¡°ë¬¸ë“¤.append(f"ì œ{ì¡°ë²ˆí˜¸}ì¡°ì˜ ì œëª©")
            if find_word in ì¡°ë‚´ìš©:
                ì¡°ë¬¸ë“¤.append(f"ì œ{ì¡°ë²ˆí˜¸}ì¡°")
            for í•­ in article.findall("í•­"):
                í•­ë²ˆí˜¸ = í•­.findtext("í•­ë²ˆí˜¸", "") or ""
                í•­ë‚´ìš© = í•­.findtext("í•­ë‚´ìš©", "") or ""
                if find_word in í•­ë‚´ìš©:
                    ì¡°ë¬¸ë“¤.append(f"ì œ{ì¡°ë²ˆí˜¸}ì¡°ì œ{í•­ë²ˆí˜¸}í•­")
        if ì¡°ë¬¸ë“¤:
            ì¡°ë¬¸_str = " ë° ".join(sorted(set(ì¡°ë¬¸ë“¤)))
            amendments.append(f"â‘  {law['ë²•ë ¹ëª…']} ì¼ë¶€ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ê°œì •í•œë‹¤. {ì¡°ë¬¸_str} ì¤‘ â€œ{find_word}â€{ì¡°ì‚¬} ê°ê° â€œ{replace_word}â€ë¡œ í•œë‹¤.")
    return amendments or ["âš ï¸ ê°œì • ëŒ€ìƒ ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."]

